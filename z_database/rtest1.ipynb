#!/usr/bin/python3

import sys,os
import bz2
import rpy2
import time
import pickle
import numpy as np
import pandas as pd

from collections import Counter
from argparse import ArgumentParser

import sklearn
from sklearn.ensemble import RandomForestClassifier

from x_kinfo_rf_gen import PrepareTrainingSet
from x_kinfo_rf_gen import dfg_state, dfg_state
from x_kinfo_rf_gen import kinfo_state, state_kinfo

from x_kinfo_traj_R import R_Impute
from x_kinfo_traj_R import R_RunRandomForest
from x_kinfo_traj_R import R_TrainRandomForest

print(np.__version__)
print(pd.__version__)
print(sklearn.__version__)

Ref_Matrx_cols= ['Group','training','p1p1x','p2p2x','r3r3x','h_cgvc',
                 'ang_NHs','ang_CHs','dist_NH','dist_CH']

Ref_Train_Cols= ['Group','p1p1x','p2p2x','r3r3x','h_cgvc','ang_NHs','ang_CHs',
                 'dist_NH','dist_CH']

Ref_Test_Cols = ['p1p1x','p2p2x','r3r3x','h_cgvc','ang_NHs','ang_CHs',
                 'dist_NH','dist_CH']

Ref_Final_Cols= ['Class','cidi_prob','cido_prob','codi_prob','codo_prob','wcd_prob',
                 'dfg_conf','dfg_prob','p1p1x','p2p2x','r3r3x','h_cgvc',
                 'ang_NHs','ang_CHs','dist_NH','dist_CH']

norm_cols = ['ang_NHs','ang_CHs','dist_NH','dist_CH']

dfg_train_cols = ['p1p1x','p2p2x','r3r3x','dist_NH','dist_CH']
full_train_cols= ['h_cgvc','ang_NHs','ang_CHs','dist_NH','dist_CH','dfg_conf']

R_dfg_model = 'R_rf_model_dfg.190527.rda'
R_chx_model = 'R_rf_model_full.190527.rda'

sk_dfg_model = 'SK_rf_model_dfg.190527.pkl.bz2'
sk_chx_model = 'SK_rf_model_full.190527.pkl.bz2'

lib_dir = '~/Dropbox (Schlessinger lab)/9_scripts/3_program/structures/4_Konformation/z_database/'
wrk_dir = '~/Dropbox (Schlessinger lab)/z_others/8_strada/'

#lib_dir = '~/Dropbox/9_scripts/3_program/structures/4_Konformation/z_database/'
#wrk_dir = '~/Dropbox/z_others/8_strada/'

#########################################################################
os.chdir('/Users/pmung')
p_rf_models, r_rf_models = [], []
data_df  = pd.read_csv(lib_dir+'stdy_kinase.param.171009.csv', delimiter=',', index_col=0)
matrx_df = data_df[Ref_Matrx_cols].drop(['1atp_E'], axis=0) # internal check
data_df[:5]
matrx_df[:5]

##################################
train_x  = PrepareTrainingSet( True, matrx_df, Ref_Train_Cols )
test_x   = matrx_df[pd.isna(matrx_df.Group) & pd.isna(matrx_df.training)]
test_x   = test_x.drop('training',axis=1).dropna(subset=Ref_Test_Cols)
complete = pd.concat([train_x, test_x])

with open('SK_normalize_param.pkl', 'rb') as fi:
  norm_parm = pickle.load(fi)

%timeit  Normalization(complete[norm_cols], norm_parm.mean, norm_parm.max)

complete = pd.read_csv('SK_rf_dataset_normalized.190527.csv.gz',sep=',',index_col='pdb_id', )

train_df = complete[ :len(train_x)]
test_df  = complete[len(train_x): ]

p_rf_models = SK_TrainRandomForest( train_df )
rf_df = SK_RunRandomForest(test_df, models=p_rf_models, Cols=Ref_Final_Cols )


## get the 'test' set without manual annotation
## there are a group in 'training' with '99' that are bad PDB and will be ignored
test_df = test_df.replace(np.nan, 'NaN').drop(['training'], axis=1)
test_df[-15:]
type(test_df.ang_NHs['5LWM_A'])


#############################################################################
def main():
  args = UserInput()

#### training random forest model ########
  if args.run_train:
    train_x = PrepareTrainingSet( args.r_impute, matrx_df, Ref_Train_Cols )
    test_x   = matrx_df[pd.isna(matrx_df.Group) & pd.isna(matrx_df.training)]
    test_x   = test_x.drop('training',axis=1).dropna(subset=Ref_Test_Cols)
    complete = pd.concat([train_x, test_x])
    complete[norm_cols] = Normalization(complete[norm_cols])

    train_df = complete[ :len(train_x)]
    test_df  = complete[len(train_x): ].drop('Group',axis=1)

    if args.r_rf:
      r_rf_models = R_TrainRandomForest( train_df, lib_dir )
    else:
      p_rf_models = SK_TrainRandomForest( args, train_df )


#### run trained random forest model ####
  test_df = PrepareTestSet( args, Ref_Test_Cols )
  if args.r_rf:
    rf_df = R_RunRandomForest(  test_df, models=r_rf_models, dir=lib_dir,
                                R_dfg_model=R_dfg_model,
                                R_chx_model=R_chx_model )
  else:
    rf_df = SK_RunRandomForest( test_df, models=p_rf_models )
    rf_df.Class.value_counts()
    rf_df[-5:]

#### Output results ####
  rf_df.to_csv(args.outpref+'kinfo.csv', sep=',')

#### Draw results ####

  # Bar chart of Kinformation distribution

  # Occurance of Kinformation along trajectory

  # 

#######################################################################
##########################################################################
def SK_RunRandomForest( traj, models='' ):

  ## load in RF models if it is not generated on the fly
  if not models:
    print('## INFO: Loading SK RandomForest models...')
    try:
      with bz2.open(lib_dir+sk_dfg_model, 'rb') as fd:
        rfc_dfg = pickle.load(fd)
    except FileNotFoundError:
      sys.exit('  ERROR: SK RandomForest model not found: '+sk_dfg_model)
    try:
      with bz2.open(lib_dir+sk_chx_model, 'rb') as fc:
        rfc = pickle.load(fc)
    except FileNotFoundError:
      sys.exit('  ERROR: SK RandomForest model not found: '+sk_chx_model)
  else:
    rfc_dfg, rfc = models

  ##### classify DFG conformation of trajectory frames #####
  start = time.perf_counter()
  traj_dfg_pred = rfc_dfg.predict(traj[dfg_train_cols])
  traj_dfg_prob = rfc_dfg.predict_proba(traj[dfg_train_cols])

  # append 'dfg_conf' and probability data to traj frame data
  traj['dfg_conf'] = traj_dfg_pred
  traj['dfg_prob'] = np.max(traj_dfg_prob, axis=1)
  print('dfg: {:.6f} s'.format((time.perf_counter()-start)))

  ##### classify Chelix/DFG conformation of traj frames #####
  start = time.perf_counter()
  traj_full_pred = rfc.predict(traj[full_train_cols])
  traj_full_prob = rfc.predict_proba(traj[full_train_cols])
  print('full: {:.6f} s'.format((time.perf_counter()-start)))

  ## append 'Class' and probability to traj frame data 
  Prob_Cols = ['cidi_prob','cido_prob','codi_prob','codo_prob','wcd_prob']
  start = time.perf_counter()
  traj['dfg_conf'] = state_dfg(pd.DataFrame(traj_dfg_pred))
  traj['Class']    = state_kinfo(pd.DataFrame(traj_full_pred))
  traj[Prob_Cols]  = traj_full_prob
  print('add: {:.6f} s'.format((time.perf_counter()-start)))

  return traj[Ref_Final_Cols]


#######################################################################
## Load the trajectory structural data and reorder the columns
def PrepareTestSet( args, Ref_Test_Cols ):
  test_df = pd.read_csv(args.test, header=True, delimiter=',')

  ## make sure the arrangement of columns is consistent
  try:
    test_df = test_df[Ref_Test_Cols]
  except IndexError:
    print(' # ERROR: expected input column name and order:')
    print(Ref_Test_Cols)
    print(test_df.columns)
    sys.exit('  Input dataset columns not matching')
  
  return test_df
  

##########################################################################
## old half-vectorized ~ 1.2s for 3800 items, full-vectorized ~5ms, ~240x speedup
def dfg_state( conf ):
  conf_di = (conf == 'cidi') | (conf == 'codi')
  conf_do = (conf == 'cido') | (conf == 'codo')
  state = pd.DataFrame({ '0': [2]*len(conf) }) # 'interm' has '2'
  state[conf_di == True] = 0  # any DI is '0'
  state[conf_do == True] = 1  # any DO is '1'
  return state['0'].to_numpy()


def state_dfg( state ):
  conf_di = (state == 0)
  conf_do = (state == 1)
  conf = pd.DataFrame({ '0': ['other']*len(state) })
  conf[conf_di[0].to_numpy() == True] = 'di' # any DI is '0'
  conf[conf_do[0].to_numpy() == True] = 'do' # any DO is '1'
  return conf['0'].to_numpy()

def state_dfg_old( state ):
  conf_di = (state == 0)
  conf_do = (state == 1)
  conf = ['other']*(len(state))   # other has '2'
  for i in range(len(state)):
    if conf_di.iloc[i][0]: conf[i] = 'di'  # any DI has '0'
    if conf_do.iloc[i][0]: conf[i] = 'do'  # any DO has '1'
  return conf

#################

def kinfo_state( conf ):
  conf_cidi = (conf == 'cidi')
  conf_cido = (conf == 'cido')
  conf_codi = (conf == 'codi')
  conf_codo = (conf == 'codo')
  state = pd.DataFrame({ '0': [4]*len(conf) }) # 'wcd' has '4'
  state[conf_cidi == True] = 0  # any DI is '0'
  state[conf_cido == True] = 1  # any DO is '1'
  state[conf_codi == True] = 2  # any DI is '0'
  state[conf_codo == True] = 3  # any DO is '1'
  return state['0'].to_numpy()

################
def state_kinfo( state ):
  conf_cidi = (state == 0)
  conf_cido = (state == 1)
  conf_codi = (state == 2)
  conf_codo = (state == 3)
  conf = pd.DataFrame({ '0': ['wcd']*len(state) })
  conf[conf_cidi[0].to_numpy() == True] = 'cidi'  # ci DI is '0'
  conf[conf_cido[0].to_numpy() == True] = 'cido'  # ci DO is '1'
  conf[conf_codi[0].to_numpy() == True] = 'codi'  # co DI is '2'
  conf[conf_codo[0].to_numpy() == True] = 'codo'  # co DO is '3'
  return conf['0'].to_numpy()


#####################################################
def UserInput():
  p = ArgumentParser(description='Command Line Arguments')

  p.add_argument('-use_r_impute', action='store_true',
                 help='Use R::randomForest::rfImpute instead of SKLearn Imputer (def: False)')

  p.add_argument('-use_r_rf', action='store_true',
                 help='Use R::randomForest instead of SKLearn RFClassifier (def: False)')

  p.add_argument('-run_train', dest='run_train', action='store_true',
                 help='Run RandomForest training (def: False)')

  p.add_argument('-save_rf', dest='save_rf', action='store_true',
                 help='Save RandomForest models (def: False)')

  p.add_argument('-traj', dest='traj_file', required=False,
                 help='Trajectory file, or an ordered list of traj filenames')
  
  p.add_argument('-out', dest='outpref', required=False,
                 help='Output prefix')

  p.add_argument('-pkl', dest='pkl', required=False,
                 help='Use pre-pickled data (def: False)')

  args=p.parse_args()
  return args

######################################################################
if __name__ == '__main__':
  main()

######################################################################
